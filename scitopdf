#!/bin/bash
#
# Download articles from Sci-Hub

#########################################
# Folder in which article is downloaded #
#########################################
destination=$HOME/downloads/scihub

if ! [ -d $destination ]; then
	mkdir $destination
fi

##############
# Functions  #
########################
# Find Sci-Hub website #
########################
localiser_site() {
site=$(curl -s -LH "" "https://sci-hub.now.sh/" | grep -i https://sci-hub... | grep -i biglink | tail -n 1 | grep -io https://sci-hub... | tail -n 1)
if [[ 'ping $(echo $site | cut -c9-100) | grep -io inconnu' = "inconnu" ]]; then #à modifier pour fonctionnement qqsoit la langue
	echo "Sci-Hub introuvable."
	$(exec $BROWSER "https://sci-hub.now.sh/")
	exit 1
else
	echo Sci-Hub is here : $site
fi
}

#####################
# Find and download #
#####################
recherche_article() {
if ! [[ $(echo "$concatener") = "" ]]; then
	recherche=$(echo $concatener | sed "s/'/\ /g" | sed 's/\ /+/g' | iconv -f utf8 -t ascii//TRANSLIT)
	if [[ $(echo $(curl -A "Mozilla/5.0 (x11; ubuntu; linux x86_64; rv:59.0) gecko/20100101 firefox/59.0" "https://search.crossref.org/?q=$recherche&from_ui=yes") | grep -io "$concatener" | head -n 1) = "$concatener" ]]; then
		echo "Title found on Crossref."
		echo "Looking for DOI."
		doi=$(echo $(curl -A "Mozilla/5.0 (x11; ubuntu; linux x86_64; rv:59.0) gecko/20100101 firefox/59.0" "https://search.crossref.org/?q=$recherche&from_ui=yes" | grep -io "https://doi.*" | grep -io "doi.*" | sed 's/http:\/\///' | grep -io "/.*" | sed 's/\///' | head -n 2 | tail -n 1))
		if [[ $(echo $doi | grep -io "doi:") = "doi:" || $(echo $doi | grep -io "doi.") = "doi." ]]; then
			echo ""
			echo "DOI for "$concatener" found : $doi"
			echo ""
			doi=$(echo $doi | sed 's/http:\/\///' | grep -io "/.*" | sed 's/\///')
		fi
	lien_telechargement=$(echo $(curl -s $site/$doi) | grep -io "<iframe\ src\ =\ \"https.*\.pdf" | sed 's/<iframe\ src\ \=\ \"//')
	nom_fichier=$(echo $lien_telechargement | sed 's:.*/::')
	cd $destination
	echo "Downloading '$nom_fichier' to '$destination'."
	curl -s "$lien_telechargement" --output "$nom_fichier"
	echo "Done."
	fi
else
	$BROWSER "$site"
fi
}

###########################################
# Option to download articles from a list #
###########################################
# Arguments evaluation : if "-l" or "--list" as first argument, then scitopdf will look inside a .txt file (2nd argument) containing several articles' titles
if [[ $(echo $1) = "-l" || $(echo $1) = "--list" ]]; then
	localiser_site
	while read line; do concatener=$(echo $line);  recherche_article "$line"; done < $2
	exit 1
else

# If no option specified, then every word following scitopdf is considered as the title (note that it can contain name of author, year, etc. with no problem)
	# regrouper tous les arguments dans une liste :
	args=("$@")
	# nombre d'arguments
	ELEMENTS=${#args[@]}
	# pour chaque élément de la liste d'arguments, les concatener
	for (( i=0;i<$ELEMENTS;i++)); do
	    concatener=$(echo $concatener" ")$(echo -n ${args[${i}]}"\ ")
	done
fi

concatener=$(echo $concatener | sed 's/\\//g')

localiser_site
recherche_article

exit


# script modifié le 4 avril 2021
