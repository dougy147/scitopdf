#!/bin/bash
#
# Download articles from Sci-Hub

#########################################
# Folder in which article is downloaded #
#########################################
destination=$HOME/downloads/scihub

if ! [ -d $destination ]; then
	mkdir $destination
fi

############################
# Check internet connexion #
############################
statut_connexion=$(echo $(ping -q -w1 -c1 google.com &>/dev/null && echo online || echo offline))
if [ $(echo $statut_connexion) = "offline" ]; then
	echo No internet connexion.
	exit 1
fi

#########################################
# Open PDF automatically after download #
#########################################
automatically_open="yes"

##############
# Functions  #
##############

	########################
	# Find Sci-Hub website #
	########################
localiser_site() {
echo "Looking for website..."
site=$(curl -s -LH "" "https://sci-hub.now.sh/" | grep -i https://sci-hub... | grep -i biglink | tail -n 1 | grep -io https://sci-hub... | tail -n 1)
echo "Checking connexion to : $site"
if [[ $(echo $(curl -v $site 2>&1) | grep -io "Could not resolve" | tail -n 1) = $(echo "Could not resolve") ]]; then
	echo "Sci-Hub's website not found. Check https://sci-hub.now.sh/"
	exit 1
else
	echo $site > /tmp/sci_address
	echo Sci-hub is here : $site
fi
}

	####################
	# Look for article #
	####################
recherche_article() {
if ! [[ $(echo "$concatener") = "" ]]; then
	recherche=$(echo $concatener | sed "s/'/\ /g" | sed 's/\ /+/g' | iconv -f utf8 -t ascii//TRANSLIT)
	notify-send "Scitopdf : recherche '$(echo $recherche | sed 's/+/\ /g')'"
	if [[ $(echo $(curl -A "Mozilla/5.0 (x11; ubuntu; linux x86_64; rv:59.0) gecko/20100101 firefox/59.0" -s "https://search.crossref.org/?q=$recherche&from_ui=yes") | grep -io "$concatener" | head -n 1) = "$concatener" ]]; then
		recherche_doi
	fi
	lien_telechargement=$(echo $(curl -s $site/$doi) | grep -io "<iframe\ src\ =\ \"https.*\.pdf" | sed 's/<iframe\ src\ \=\ \"//')
	nom_fichier=$(echo $lien_telechargement | sed 's:.*/::')
	cd $destination
	if [[ $(echo $nom_fichier) == "" ]]; then
		notify-send "Pdf non téléchargé."
		echo "Article not found. Please check if your country is not blocking access to Sci-Hub. Use a VPN if possible."
		exit;
	else
		echo "Downloading '$nom_fichier' to '$destination'."
		curl -s "$lien_telechargement" --output "$nom_fichier"
		notify-send "$nom_fichier téléchargé."
		echo "Done."
		if [ $(echo $automatically_open) = "yes" ]; then
			setsid $READER "$destination/$nom_fichier"
		fi
	fi
else
	echo "Paste informations (title, or DOI, http address, authors' names, year, journal ...) : "
	read concatener
	recherche_article
fi
}

	############################
	# Look for DOI on Crossref #
	############################
recherche_doi() {
echo "Paper found on Crossref. Looking for DOI."
doi=$(echo $(curl -A "Mozilla/5.0 (x11; ubuntu; linux x86_64; rv:59.0) gecko/20100101 firefox/59.0" -s "https://search.crossref.org/?q=$recherche&from_ui=yes" | grep -io "https://doi.*" | grep -io "doi.*" | sed 's/http:\/\///' | grep -io "/.*" | sed 's/\///' | head -n 2 | tail -n 1))
if ! [[ $(echo $doi) = "" ]]; then
	if [[ $(echo $doi | grep -io "doi:") = "doi:" || $(echo $doi | grep -io "doi.") = "doi." ]]; then
		echo ""
		echo "DOI for "$concatener" found : $doi"
		echo ""
		doi=$(echo $doi | sed 's/http:\/\///' | grep -io "/.*" | sed 's/\///')
	fi
	echo "DOI for "$concatener" found : $doi"
else
	echo "DOI not found."
	exit 1;
fi
}

###########################################
# Option to download articles from a list #
###########################################
# Arguments evaluation : if "-l" or "--list" as first argument, then scitopdf will look inside a .txt file (2nd argument) which would contain several references
if [[ $(echo $1) = "-l" || $(echo $1) = "--list" ]]; then
	automatically_open="no"
	localiser_site
	while read line; do concatener=$(echo $line);  recherche_article "$line"; done < $2
	exit 1
else
# If no option specified, then every word following scitopdf is considered as the title (note that it can contain name of author, year, etc. with no problem)
	# regrouper tous les arguments
	# regrouper les arguments dans une liste
	args=("$@")
	# nombre d'arguments
	ELEMENTS=${#args[@]}
	# echo chaque element dans une liste
	# for loop
	for (( i=0;i<$ELEMENTS;i++)); do
	    #echo -n ${args[${i}]}"\ "
	    concatener=$(echo $concatener" ")$(echo -n ${args[${i}]}"\ ")
	done
fi


################
# Start script #
################

if [[ $(echo $concatener | grep -io http) == "http" ]]; then
	localiser_site
	concatener=$(echo $concatener | sed "s/'//g" | sed 's/\ //g' | sed 's/\\//g')
	lien_telechargement=$(echo $(curl -s $site/$concatener) | grep -io "<iframe\ src\ .*\.pdf" | sed 's/<iframe\ src\ =\ \"//g')
	if [[ $(echo $lien_telechargement | cut -c1-2) == "//" ]]; then
		lien_telechargement=$(echo $lien_telechargement | sed 's/\/\//https:\/\//g')
	fi
	nom_fichier=$(echo $lien_telechargement | sed 's:.*/::')
	cd $destination
	if [[ $(echo $nom_fichier) == "" ]]; then
		notify-send "Pdf non téléchargé."
		echo "Article not found. Please check if your country is not blocking access to Sci-Hub. Use a VPN if possible."
		exit;
	else
		echo "Downloading '$nom_fichier' to '$destination'."
		curl -s "$lien_telechargement" --output "$nom_fichier"
		notify-send "$nom_fichier téléchargé."
		echo "Done."
		if [ $(echo $automatically_open) = "yes" ]; then
			setsid $READER "$destination/$nom_fichier"
		fi
	fi
else
	concatener=$(echo $concatener | sed 's/\\//g')

	if [[ $(cat /tmp/sci_address 2> /dev/null) == "" ]]; then
		rm /tmp/sci_address 2> /dev/null
		localiser_site
	fi

	if [ -f /tmp/sci_address ]; then
		site=$(echo $(cat /tmp/sci_address))
		recherche_article
	else
		localiser_site
		site=$(echo $(cat /tmp/sci_address))
		recherche_article
	fi
fi


exit

# script modifié le 6 avril 2021
